# [首页<<](../../index.html)


# 线代之几何重数&代数重数的理解(1)

---

## 前言

因为线性代数并没有讲过约当标准型，所以导致我们在学习现代控制理论的时候一脸懵，今天来对自己理解的一些东西做一个非常浅显的总结，并且对很久之前学过的线性代数一些内容做复习

---

## 正文

#### 首先我们来看特征值、特征向量的定义

设 A 为 n 阶方阵，如果存在$\lambda$和 n 维非零向量$\alpha$使得

$$A\alpha=\lambda\alpha$$

则我们把$\lambda$称为方阵的一个**特征值**，$\alpha$称为方阵 A 对应于**特征值$\lambda$的一个特征向量**  
首先求特征值用到的公式是
$$\det(\lambda*I-A)=0$$  
这里有两个性质比较有意思
$$\lambda1+\lambda2+...+\lambda_n=tr(A)$$
$$\lambda1\lambda2···\lambda_n=\det A$$
即所有特征值之和等于矩阵 A 的对角线上的元的和  
所有特征值之积等于 A 的行列式的值

#### 化简特征方程

我们知道特征方程最后解出来是特征值，所以我们可以把方程的形式表示为一个根次方乘积的形式，即：
$$|\lambda I-A|=(\lambda-\lambda_1)^{k1}(\lambda-\lambda_2)^{k2}···(\lambda-\lambda_n)^{kn}$$

那么这里的$\lambda_1到\lambda_n$就是解出来的特征值  
$k_1到k_n$代表对应特征值的重根数

例如:  
$$|\lambda I-A|=(\lambda-2)^{2}(\lambda+7)^{1}$$

其中:  
$\lambda_1$的解为 2，重根数 2 个，代数重数等于重根数，等于 2 个
$\lambda_2$的解为-7，重根数 1 个，代数重数等于重根数，等于 1 个

**请注意，这里描述的代数重数都是指$\lambda$的代数重数**

那么在说到几何重数之前就必须讲讲**特征子空间**了

#### 特征子空间

定义：
$V_\lambda$即特征子空间指的是对方阵 A 来说，对应的特征值的所有的特征向量和零向量所组成的空间集合  
大白话就是分别代入所有的特征值进去解 x，也就是特征向量: $(\lambda_{1...n} I-A)x=0$
<font color="red">请还是注意，这里的特征子空间还是对于特定的特征值来说的</font>

#### 几何重数

为什么要强调这个，因为和几何重数的定义息息相关

几何重数就定义成：
$\lambda_i$的特征子空间$V_{\lambda i}$的维数
其中可以证明：**特征值的几何重数不大于它的代数重数**

关于几何重数有公式可以表达
$$几何重数=dim(V_\lambda)=n-R(\lambda I-A)$$

就是$\lambda$带入方程后所得到的方程**缺少**的秩的数目

#### 实例

---

求解
$A=\begin{pmatrix} 
1 & -2 & 2 
\\
-2 & -2 &4
\\
2 & 4 & -2
\end{pmatrix}的特征值与特征向量，特征子空间
$

---

解：
$$|\lambda I-A|=(\lambda-2)^{2}(\lambda+7)^{1}$$
$\lambda_1$的解为 2，重根数 2 个
$\lambda_2$的解为-7，重根数 1 个

将$\lambda_1$带入后变成$(2I-A)x=0$
化简得到
$$x_1+2x_2-2x_3=0$$
三个未知数一个方程
我们需要解出解系，我们令$x_1=-2k_1,x_2=k_1$解得$x_3=0$
解出第一个特征向量$\alpha_1$为

$$
\alpha_1=k1\begin{pmatrix}
-2
\\
1
\\
0
\end{pmatrix}
$$

同理解出第二个特征向量$\alpha_2$为

$$
\alpha_2=k2\begin{pmatrix}
2
\\
0
\\
1
\end{pmatrix}
$$

其中 k1,k2 不同时为 0

我们带入$\lambda_2$带入后解$(-7I-A)x=0$

$$
\left\{
\begin{aligned}
2x_1+x_3= 0\\
x_2+x_3=0
\end{aligned}
\right.
$$

解出

$$
\alpha_3=k3\begin{pmatrix}
1
\\
2
\\
-2
\end{pmatrix}
$$

那么根据定义，

$$
V_{\lambda_1}=\begin{pmatrix}
\alpha_1 , \alpha_2 ,0
\end{pmatrix}
$$

就是$\lambda_1$和$\lambda_2$的特征子空间

$$
V_{\lambda_3}=\begin{pmatrix}
\alpha_3,0
\end{pmatrix}
$$

就是$\lambda_3$的特征子空间，那么对于$\lambda_1,\lambda_2$来说，它们的几何重数为$\dim(V_{\lambda_1})$或$\dim(V_{\lambda_2})$，特征子空间的维度就等于基向量个数，这里有两个基向量$\alpha_1,\alpha_2$所以几何重数就是 2
对于$\lambda_3$来说只有一个基向量，所以就是几何重数为 1

### 总结

关于**特征值的几何重数不大于它的代数重数**的证明，可以看这里的回答
[https://www.zhihu.com/question/414388172](https://www.zhihu.com/question/414388172)

那么下一篇将会讲约当标准型、广义特征向量和几何重数代数重数之间的关系

（逃）

### 传送门
[线性代数之几何重数&代数重数的理解(二)-矩阵指数的求解](./线性代数之几何重数&代数重数的理解(二)-矩阵指数的求解.html)

------

<div id = 'time'>2月14日 星期2 1时 11分 52秒</div>

作者：Onion

邮箱：bigonion@bigonion.cn

声明：未经本人同意，禁止转载、搬运、抄袭！

 <!-- $$
\begin{gathered}
\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}
\quad
\begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix}
\quad
\begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix}
\quad
\begin{Bmatrix} 1 & 0 \\ 0 & -1 \end{Bmatrix}
\quad
\begin{vmatrix} a & b \\ c & d \end{vmatrix}
\quad
\begin{Vmatrix} i & 0 \\ 0 & -i \end{Vmatrix}
\end{gathered}
$$ -->
